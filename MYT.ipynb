{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Imports "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {},
      "outputs": [],
      "source": [
        "import sys\n",
        "# sys project root\n",
        "sys.path.append('/home/yigit/codebase/emg2qwerty')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Train & Evaluate TDS ConvNet (Baseline)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nSoRzGXCfUtz"
      },
      "source": [
        "### Step 1: Start your experiments!\n",
        "\n",
        "- Remember to download and copy the dataset to this directory: `Your_Dir/emg2qwerty/data`.\n",
        "- You may now start your experiments with any scripts! Below are examples of single-user training and testing (greedy decoding).\n",
        "- **There are two ways to track the logs:**\n",
        "  - 1. Keep `--multirun`, and the logs will not be printed here, but they will be saved in the folder `logs`, e.g., `logs/2025-02-09/18-24-15/submitit_logs/`.\n",
        "  - 2. Comment out `--multirun` and the logs will be printed in this notebook, but they will not be saved."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IVuSn4rXhLJa"
      },
      "source": [
        "#### Training\n",
        "\n",
        "- The checkpoints are saved in the folder `logs`, e.g., `logs/2025-02-09/18-24-15/checkpoints/`."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "n84M6KLmkp2i"
      },
      "outputs": [],
      "source": [
        "# Single-user training\n",
        "!HYDRA_FULL_ERROR=1 python -m emg2qwerty.train \\\n",
        "  user=\"glob(single_user)\" \\\n",
        "  trainer.accelerator=gpu trainer.devices=4 \\\n",
        "  --multirun"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {},
      "outputs": [],
      "source": [
        "# get plots from tensorboard and show them in the notebook\n",
        "%load_ext tensorboard"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "Reusing TensorBoard on port 6006 (pid 1728857), started 0:12:20 ago. (Use '!kill 1728857' to kill it.)"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "\n",
              "      <iframe id=\"tensorboard-frame-4c31dedb457e7447\" width=\"100%\" height=\"800\" frameborder=\"0\">\n",
              "      </iframe>\n",
              "      <script>\n",
              "        (function() {\n",
              "          const frame = document.getElementById(\"tensorboard-frame-4c31dedb457e7447\");\n",
              "          const url = new URL(\"http://localhost\");\n",
              "          const port = 6006;\n",
              "          if (port) {\n",
              "            url.port = port;\n",
              "          }\n",
              "          frame.src = url;\n",
              "        })();\n",
              "      </script>\n",
              "    "
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "%tensorboard --logdir logs/2025-03-08/BASELINE/"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MGANotiwhngl"
      },
      "source": [
        "#### Testing:\n",
        "\n",
        "- Replace `Your_Path_to_Checkpoint` with your checkpoint path."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "id": "p68aDt-8pmGj"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[2025-03-08 15:02:17,292][__main__][INFO] - \n",
            "Config:\n",
            "user: single_user\n",
            "dataset:\n",
            "  train:\n",
            "  - user: 89335547\n",
            "    session: 2021-06-03-1622765527-keystrokes-dca-study@1-0efbe614-9ae6-4131-9192-4398359b4f5f\n",
            "  - user: 89335547\n",
            "    session: 2021-06-02-1622681518-keystrokes-dca-study@1-0efbe614-9ae6-4131-9192-4398359b4f5f\n",
            "  - user: 89335547\n",
            "    session: 2021-06-04-1622863166-keystrokes-dca-study@1-0efbe614-9ae6-4131-9192-4398359b4f5f\n",
            "  - user: 89335547\n",
            "    session: 2021-07-22-1627003020-keystrokes-dca-study@1-0efbe614-9ae6-4131-9192-4398359b4f5f\n",
            "  - user: 89335547\n",
            "    session: 2021-07-21-1626916256-keystrokes-dca-study@1-0efbe614-9ae6-4131-9192-4398359b4f5f\n",
            "  - user: 89335547\n",
            "    session: 2021-07-22-1627004019-keystrokes-dca-study@1-0efbe614-9ae6-4131-9192-4398359b4f5f\n",
            "  - user: 89335547\n",
            "    session: 2021-06-05-1622885888-keystrokes-dca-study@1-0efbe614-9ae6-4131-9192-4398359b4f5f\n",
            "  - user: 89335547\n",
            "    session: 2021-06-02-1622679967-keystrokes-dca-study@1-0efbe614-9ae6-4131-9192-4398359b4f5f\n",
            "  - user: 89335547\n",
            "    session: 2021-06-03-1622764398-keystrokes-dca-study@1-0efbe614-9ae6-4131-9192-4398359b4f5f\n",
            "  - user: 89335547\n",
            "    session: 2021-07-21-1626917264-keystrokes-dca-study@1-0efbe614-9ae6-4131-9192-4398359b4f5f\n",
            "  - user: 89335547\n",
            "    session: 2021-06-05-1622889105-keystrokes-dca-study@1-0efbe614-9ae6-4131-9192-4398359b4f5f\n",
            "  - user: 89335547\n",
            "    session: 2021-06-03-1622766673-keystrokes-dca-study@1-0efbe614-9ae6-4131-9192-4398359b4f5f\n",
            "  - user: 89335547\n",
            "    session: 2021-06-04-1622861066-keystrokes-dca-study@1-0efbe614-9ae6-4131-9192-4398359b4f5f\n",
            "  - user: 89335547\n",
            "    session: 2021-07-22-1627001995-keystrokes-dca-study@1-0efbe614-9ae6-4131-9192-4398359b4f5f\n",
            "  - user: 89335547\n",
            "    session: 2021-06-05-1622884635-keystrokes-dca-study@1-0efbe614-9ae6-4131-9192-4398359b4f5f\n",
            "  - user: 89335547\n",
            "    session: 2021-07-21-1626915176-keystrokes-dca-study@1-0efbe614-9ae6-4131-9192-4398359b4f5f\n",
            "  val:\n",
            "  - user: 89335547\n",
            "    session: 2021-06-04-1622862148-keystrokes-dca-study@1-0efbe614-9ae6-4131-9192-4398359b4f5f\n",
            "  test:\n",
            "  - user: 89335547\n",
            "    session: 2021-06-02-1622682789-keystrokes-dca-study@1-0efbe614-9ae6-4131-9192-4398359b4f5f\n",
            "  root: ${hydra:runtime.cwd}/data\n",
            "to_tensor:\n",
            "  _target_: emg2qwerty.transforms.ToTensor\n",
            "  fields:\n",
            "  - emg_left\n",
            "  - emg_right\n",
            "band_rotation:\n",
            "  _target_: emg2qwerty.transforms.ForEach\n",
            "  transform:\n",
            "    _target_: emg2qwerty.transforms.RandomBandRotation\n",
            "    offsets:\n",
            "    - -1\n",
            "    - 0\n",
            "    - 1\n",
            "temporal_jitter:\n",
            "  _target_: emg2qwerty.transforms.TemporalAlignmentJitter\n",
            "  max_offset: 120\n",
            "logspec:\n",
            "  _target_: emg2qwerty.transforms.LogSpectrogram\n",
            "  n_fft: 64\n",
            "  hop_length: 16\n",
            "specaug:\n",
            "  _target_: emg2qwerty.transforms.SpecAugment\n",
            "  n_time_masks: 3\n",
            "  time_mask_param: 25\n",
            "  n_freq_masks: 2\n",
            "  freq_mask_param: 4\n",
            "transforms:\n",
            "  train:\n",
            "  - ${to_tensor}\n",
            "  - ${band_rotation}\n",
            "  - ${temporal_jitter}\n",
            "  - ${logspec}\n",
            "  - ${specaug}\n",
            "  val:\n",
            "  - ${to_tensor}\n",
            "  - ${logspec}\n",
            "  test: ${transforms.val}\n",
            "module:\n",
            "  _target_: emg2qwerty.lightning.TDSConvCTCModule\n",
            "  in_features: 528\n",
            "  mlp_features:\n",
            "  - 384\n",
            "  block_channels:\n",
            "  - 24\n",
            "  - 24\n",
            "  - 24\n",
            "  - 24\n",
            "  kernel_width: 32\n",
            "datamodule:\n",
            "  _target_: emg2qwerty.lightning.WindowedEMGDataModule\n",
            "  window_length: 8000\n",
            "  padding:\n",
            "  - 1800\n",
            "  - 200\n",
            "optimizer:\n",
            "  _target_: torch.optim.Adam\n",
            "  lr: 0.001\n",
            "lr_scheduler:\n",
            "  scheduler:\n",
            "    _target_: pl_bolts.optimizers.lr_scheduler.LinearWarmupCosineAnnealingLR\n",
            "    warmup_epochs: 10\n",
            "    max_epochs: ${trainer.max_epochs}\n",
            "    warmup_start_lr: 1.0e-08\n",
            "    eta_min: 1.0e-06\n",
            "  interval: epoch\n",
            "decoder:\n",
            "  _target_: emg2qwerty.decoder.CTCGreedyDecoder\n",
            "seed: 1501\n",
            "batch_size: 32\n",
            "num_workers: 4\n",
            "train: false\n",
            "checkpoint: /home/yigit/codebase/emg2qwerty/logs/2025-03-08/14-10-13/Baseline/checkpoints/best_checkpoint_baseline.ckpt\n",
            "monitor_metric: val/CER\n",
            "monitor_mode: min\n",
            "trainer:\n",
            "  accelerator: gpu\n",
            "  devices: 1\n",
            "  num_nodes: 1\n",
            "  max_epochs: 150\n",
            "  default_root_dir: ${hydra:runtime.output_dir}\n",
            "callbacks:\n",
            "- _target_: pytorch_lightning.callbacks.LearningRateMonitor\n",
            "- _target_: pytorch_lightning.callbacks.ModelCheckpoint\n",
            "  dirpath: ${hydra:runtime.output_dir}/checkpoints\n",
            "  monitor: ${monitor_metric}\n",
            "  mode: ${monitor_mode}\n",
            "  save_last: true\n",
            "  verbose: true\n",
            "\n",
            "Global seed set to 1501\n",
            "[2025-03-08 15:02:17,294][__main__][INFO] - Instantiating LightningModule {'_target_': 'emg2qwerty.lightning.TDSConvCTCModule', 'in_features': 528, 'mlp_features': [384], 'block_channels': [24, 24, 24, 24], 'kernel_width': 32}\n",
            "[2025-03-08 15:02:17,375][__main__][INFO] - Loading module from checkpoint /home/yigit/codebase/emg2qwerty/logs/2025-03-08/14-10-13/Baseline/checkpoints/best_checkpoint_baseline.ckpt\n",
            "[2025-03-08 15:02:17,474][__main__][INFO] - Instantiating LightningDataModule {'_target_': 'emg2qwerty.lightning.WindowedEMGDataModule', 'window_length': 8000, 'padding': [1800, 200]}\n",
            "GPU available: True (cuda), used: True\n",
            "TPU available: False, using: 0 TPU cores\n",
            "IPU available: False, using: 0 IPUs\n",
            "HPU available: False, using: 0 HPUs\n",
            "Missing logger folder: /home/yigit/codebase/emg2qwerty/logs/2025-03-08/15-02-17/lightning_logs\n",
            "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
            "Validation DataLoader 0:   0%|                            | 0/7 [00:00<?, ?it/s]/home/yigit/anaconda3/envs/emg2qwerty/lib/python3.10/site-packages/torch/nn/modules/conv.py:456: UserWarning: Plan failed with a cudnnException: CUDNN_BACKEND_EXECUTION_PLAN_DESCRIPTOR: cudnnFinalize Descriptor Failed cudnn_status: CUDNN_STATUS_NOT_SUPPORTED (Triggered internally at /opt/conda/conda-bld/pytorch_1712608935911/work/aten/src/ATen/native/cudnn/Conv_v8.cpp:919.)\n",
            "  return F.conv2d(input, weight, bias, self.stride,\n",
            "Validation DataLoader 0: 100%|████████████████████| 7/7 [00:00<00:00,  8.04it/s]\n",
            "────────────────────────────────────────────────────────────────────────────────\n",
            "     Validate metric           DataLoader 0\n",
            "────────────────────────────────────────────────────────────────────────────────\n",
            "         val/CER             21.9317684173584\n",
            "         val/DER            1.8830305337905884\n",
            "         val/IER             5.870624542236328\n",
            "         val/SER            14.178112983703613\n",
            "        val/loss            0.8125836849212646\n",
            "────────────────────────────────────────────────────────────────────────────────\n",
            "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
            "Testing DataLoader 0: 100%|███████████████████████| 1/1 [00:01<00:00,  1.48s/it]\n",
            "────────────────────────────────────────────────────────────────────────────────\n",
            "       Test metric             DataLoader 0\n",
            "────────────────────────────────────────────────────────────────────────────────\n",
            "        test/CER            23.622217178344727\n",
            "        test/DER            2.1180031299591064\n",
            "        test/IER             4.949211120605469\n",
            "        test/SER            16.555004119873047\n",
            "        test/loss           0.8555042147636414\n",
            "────────────────────────────────────────────────────────────────────────────────\n",
            "{'val_metrics': [{'val/loss': 0.8125836849212646,\n",
            "                  'val/CER': 21.9317684173584,\n",
            "                  'val/IER': 5.870624542236328,\n",
            "                  'val/DER': 1.8830305337905884,\n",
            "                  'val/SER': 14.178112983703613}],\n",
            " 'test_metrics': [{'test/loss': 0.8555042147636414,\n",
            "                   'test/CER': 23.622217178344727,\n",
            "                   'test/IER': 4.949211120605469,\n",
            "                   'test/DER': 2.1180031299591064,\n",
            "                   'test/SER': 16.555004119873047}],\n",
            " 'best_checkpoint': ''}\n"
          ]
        }
      ],
      "source": [
        "# Single-user testing\n",
        "!python -m emg2qwerty.train \\\n",
        "  user=\"single_user\" \\\n",
        "  checkpoint=\"/home/yigit/codebase/emg2qwerty/logs/2025-03-08/14-10-13/Baseline/checkpoints/best_checkpoint_baseline.ckpt\" \\\n",
        "  train=False trainer.accelerator=gpu \\\n",
        "  decoder=ctc_greedy \\\n",
        "  hydra.launcher.mem_gb=64 \\\n",
        "  # --multirun"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### 2. CNN + LSTM Module\n",
        "- Use CNN layers to process spatial features across channels\n",
        "- Feed CNN features into LSTM layers for temporal processing\n",
        "- Project to character space"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "CNN-LSTM Architecture\n",
        "\n",
        "Input Processing:\n",
        "\n",
        "Takes the same input as the baseline model: EMG signals with shape (T, N, bands=2, channels=16, freq)\n",
        "Uses the same SpectrogramNorm as the baseline for consistent preprocessing\n",
        "\n",
        "\n",
        "CNN Feature Extractor:\n",
        "\n",
        "Processes spatial features across EMG channels\n",
        "Uses a sequence of Conv1D layers with batch normalization and ReLU activation\n",
        "Extracts increasingly complex features through multiple CNN layers\n",
        "\n",
        "\n",
        "LSTM Temporal Processor:\n",
        "\n",
        "Bidirectional LSTM to capture temporal dependencies in both directions\n",
        "Multiple LSTM layers with dropout between them for regularization\n",
        "Processes the temporal sequence of CNN features\n",
        "\n",
        "\n",
        "Output Projection:\n",
        "\n",
        "Projects LSTM outputs to character space using fully connected layers\n",
        "Includes dropout for regularization\n",
        "Ends with LogSoftmax for compatibility with CTCLoss"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[2025-03-08 16:55:01,963][HYDRA] Submitit 'local' sweep output dir : logs/2025-03-08/16-55-01\n",
            "[2025-03-08 16:55:01,964][HYDRA] \t#0 : user=single_user trainer.accelerator=gpu trainer.devices=4\n"
          ]
        }
      ],
      "source": [
        "!HYDRA_FULL_ERROR=1 python -m emg2qwerty.train \\\n",
        "  user=\"glob(single_user)\" \\\n",
        "  trainer.accelerator=gpu trainer.devices=4 \\\n",
        "  --multirun"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {},
      "outputs": [],
      "source": [
        "%load_ext tensorboard"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "Reusing TensorBoard on port 6012 (pid 1731493), started 0:00:24 ago. (Use '!kill 1731493' to kill it.)"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "\n",
              "      <iframe id=\"tensorboard-frame-c11ce306c30ee069\" width=\"100%\" height=\"800\" frameborder=\"0\">\n",
              "      </iframe>\n",
              "      <script>\n",
              "        (function() {\n",
              "          const frame = document.getElementById(\"tensorboard-frame-c11ce306c30ee069\");\n",
              "          const url = new URL(\"http://localhost\");\n",
              "          const port = 6012;\n",
              "          if (port) {\n",
              "            url.port = port;\n",
              "          }\n",
              "          frame.src = url;\n",
              "        })();\n",
              "      </script>\n",
              "    "
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "%tensorboard --logdir logs/2025-03-08/CNNLSTM/cnnlstm/ --port 6012"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[2025-03-11 01:02:51,710][__main__][INFO] - \n",
            "Config:\n",
            "user: single_user\n",
            "dataset:\n",
            "  train:\n",
            "  - user: 89335547\n",
            "    session: 2021-06-03-1622765527-keystrokes-dca-study@1-0efbe614-9ae6-4131-9192-4398359b4f5f\n",
            "  - user: 89335547\n",
            "    session: 2021-06-02-1622681518-keystrokes-dca-study@1-0efbe614-9ae6-4131-9192-4398359b4f5f\n",
            "  - user: 89335547\n",
            "    session: 2021-06-04-1622863166-keystrokes-dca-study@1-0efbe614-9ae6-4131-9192-4398359b4f5f\n",
            "  - user: 89335547\n",
            "    session: 2021-07-22-1627003020-keystrokes-dca-study@1-0efbe614-9ae6-4131-9192-4398359b4f5f\n",
            "  - user: 89335547\n",
            "    session: 2021-07-21-1626916256-keystrokes-dca-study@1-0efbe614-9ae6-4131-9192-4398359b4f5f\n",
            "  - user: 89335547\n",
            "    session: 2021-07-22-1627004019-keystrokes-dca-study@1-0efbe614-9ae6-4131-9192-4398359b4f5f\n",
            "  - user: 89335547\n",
            "    session: 2021-06-05-1622885888-keystrokes-dca-study@1-0efbe614-9ae6-4131-9192-4398359b4f5f\n",
            "  - user: 89335547\n",
            "    session: 2021-06-02-1622679967-keystrokes-dca-study@1-0efbe614-9ae6-4131-9192-4398359b4f5f\n",
            "  - user: 89335547\n",
            "    session: 2021-06-03-1622764398-keystrokes-dca-study@1-0efbe614-9ae6-4131-9192-4398359b4f5f\n",
            "  - user: 89335547\n",
            "    session: 2021-07-21-1626917264-keystrokes-dca-study@1-0efbe614-9ae6-4131-9192-4398359b4f5f\n",
            "  - user: 89335547\n",
            "    session: 2021-06-05-1622889105-keystrokes-dca-study@1-0efbe614-9ae6-4131-9192-4398359b4f5f\n",
            "  - user: 89335547\n",
            "    session: 2021-06-03-1622766673-keystrokes-dca-study@1-0efbe614-9ae6-4131-9192-4398359b4f5f\n",
            "  - user: 89335547\n",
            "    session: 2021-06-04-1622861066-keystrokes-dca-study@1-0efbe614-9ae6-4131-9192-4398359b4f5f\n",
            "  - user: 89335547\n",
            "    session: 2021-07-22-1627001995-keystrokes-dca-study@1-0efbe614-9ae6-4131-9192-4398359b4f5f\n",
            "  - user: 89335547\n",
            "    session: 2021-06-05-1622884635-keystrokes-dca-study@1-0efbe614-9ae6-4131-9192-4398359b4f5f\n",
            "  - user: 89335547\n",
            "    session: 2021-07-21-1626915176-keystrokes-dca-study@1-0efbe614-9ae6-4131-9192-4398359b4f5f\n",
            "  val:\n",
            "  - user: 89335547\n",
            "    session: 2021-06-04-1622862148-keystrokes-dca-study@1-0efbe614-9ae6-4131-9192-4398359b4f5f\n",
            "  test:\n",
            "  - user: 89335547\n",
            "    session: 2021-06-02-1622682789-keystrokes-dca-study@1-0efbe614-9ae6-4131-9192-4398359b4f5f\n",
            "  root: ${hydra:runtime.cwd}/data\n",
            "to_tensor:\n",
            "  _target_: emg2qwerty.transforms.ToTensor\n",
            "  fields:\n",
            "  - emg_left\n",
            "  - emg_right\n",
            "band_rotation:\n",
            "  _target_: emg2qwerty.transforms.ForEach\n",
            "  transform:\n",
            "    _target_: emg2qwerty.transforms.RandomBandRotation\n",
            "    offsets:\n",
            "    - -1\n",
            "    - 0\n",
            "    - 1\n",
            "temporal_jitter:\n",
            "  _target_: emg2qwerty.transforms.TemporalAlignmentJitter\n",
            "  max_offset: 120\n",
            "logspec:\n",
            "  _target_: emg2qwerty.transforms.LogSpectrogram\n",
            "  n_fft: 64\n",
            "  hop_length: 16\n",
            "specaug:\n",
            "  _target_: emg2qwerty.transforms.SpecAugment\n",
            "  n_time_masks: 3\n",
            "  time_mask_param: 25\n",
            "  n_freq_masks: 2\n",
            "  freq_mask_param: 4\n",
            "transforms:\n",
            "  train:\n",
            "  - ${to_tensor}\n",
            "  - ${band_rotation}\n",
            "  - ${temporal_jitter}\n",
            "  - ${logspec}\n",
            "  - ${specaug}\n",
            "  val:\n",
            "  - ${to_tensor}\n",
            "  - ${logspec}\n",
            "  test: ${transforms.val}\n",
            "module:\n",
            "  _target_: emg2qwerty.lightning.CNNLSTMModule\n",
            "  in_features: 528\n",
            "  cnn_channels:\n",
            "  - 32\n",
            "  - 64\n",
            "  - 128\n",
            "  - 256\n",
            "  lstm_hidden_size: 512\n",
            "  lstm_num_layers: 2\n",
            "  dropout: 0.2\n",
            "datamodule:\n",
            "  _target_: emg2qwerty.lightning.WindowedEMGDataModule\n",
            "  window_length: 8000\n",
            "  padding:\n",
            "  - 1800\n",
            "  - 200\n",
            "optimizer:\n",
            "  _target_: torch.optim.Adam\n",
            "  lr: 0.001\n",
            "lr_scheduler:\n",
            "  scheduler:\n",
            "    _target_: pl_bolts.optimizers.lr_scheduler.LinearWarmupCosineAnnealingLR\n",
            "    warmup_epochs: 10\n",
            "    max_epochs: ${trainer.max_epochs}\n",
            "    warmup_start_lr: 1.0e-08\n",
            "    eta_min: 1.0e-06\n",
            "  interval: epoch\n",
            "decoder:\n",
            "  _target_: emg2qwerty.decoder.CTCGreedyDecoder\n",
            "seed: 1501\n",
            "batch_size: 32\n",
            "num_workers: 4\n",
            "train: false\n",
            "checkpoint: /home/yigit/codebase/emg2qwerty/logs/2025-03-08/CNNLSTM/cnnlstm/checkpoints/best_checkpoint_cnn_lstm.ckpt\n",
            "monitor_metric: val/CER\n",
            "monitor_mode: min\n",
            "trainer:\n",
            "  accelerator: gpu\n",
            "  devices: 1\n",
            "  num_nodes: 1\n",
            "  max_epochs: 150\n",
            "  default_root_dir: ${hydra:runtime.output_dir}\n",
            "callbacks:\n",
            "- _target_: pytorch_lightning.callbacks.LearningRateMonitor\n",
            "- _target_: pytorch_lightning.callbacks.ModelCheckpoint\n",
            "  dirpath: ${hydra:runtime.output_dir}/checkpoints\n",
            "  monitor: ${monitor_metric}\n",
            "  mode: ${monitor_mode}\n",
            "  save_last: true\n",
            "  verbose: true\n",
            "\n",
            "Global seed set to 1501\n",
            "[2025-03-11 01:02:51,713][__main__][INFO] - Instantiating LightningModule {'_target_': 'emg2qwerty.lightning.CNNLSTMModule', 'in_features': 528, 'cnn_channels': [32, 64, 128, 256], 'lstm_hidden_size': 512, 'lstm_num_layers': 2, 'dropout': 0.2}\n",
            "[2025-03-11 01:02:51,900][__main__][INFO] - Loading module from checkpoint /home/yigit/codebase/emg2qwerty/logs/2025-03-08/CNNLSTM/cnnlstm/checkpoints/best_checkpoint_cnn_lstm.ckpt\n",
            "[2025-03-11 01:02:52,107][__main__][INFO] - Instantiating LightningDataModule {'_target_': 'emg2qwerty.lightning.WindowedEMGDataModule', 'window_length': 8000, 'padding': [1800, 200]}\n",
            "GPU available: True (cuda), used: True\n",
            "TPU available: False, using: 0 TPU cores\n",
            "IPU available: False, using: 0 IPUs\n",
            "HPU available: False, using: 0 HPUs\n",
            "Missing logger folder: /home/yigit/codebase/emg2qwerty/logs/2025-03-11/01-02-51/lightning_logs\n",
            "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
            "Validation DataLoader 0: 100%|████████████████████| 7/7 [00:01<00:00,  5.81it/s]\n",
            "────────────────────────────────────────────────────────────────────────────────\n",
            "     Validate metric           DataLoader 0\n",
            "────────────────────────────────────────────────────────────────────────────────\n",
            "         val/CER            15.130704879760742\n",
            "         val/DER            1.9494904279708862\n",
            "         val/IER            2.9020824432373047\n",
            "         val/SER            10.279131889343262\n",
            "        val/loss             0.541666567325592\n",
            "────────────────────────────────────────────────────────────────────────────────\n",
            "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
            "Testing DataLoader 0: 100%|███████████████████████| 1/1 [00:06<00:00,  6.08s/it]\n",
            "────────────────────────────────────────────────────────────────────────────────\n",
            "       Test metric             DataLoader 0\n",
            "────────────────────────────────────────────────────────────────────────────────\n",
            "        test/CER            16.598228454589844\n",
            "        test/DER             1.448022484779358\n",
            "        test/IER             3.133780002593994\n",
            "        test/SER            12.016425132751465\n",
            "        test/loss            0.581876814365387\n",
            "────────────────────────────────────────────────────────────────────────────────\n",
            "{'val_metrics': [{'val/loss': 0.541666567325592,\n",
            "                  'val/CER': 15.130704879760742,\n",
            "                  'val/IER': 2.9020824432373047,\n",
            "                  'val/DER': 1.9494904279708862,\n",
            "                  'val/SER': 10.279131889343262}],\n",
            " 'test_metrics': [{'test/loss': 0.581876814365387,\n",
            "                   'test/CER': 16.598228454589844,\n",
            "                   'test/IER': 3.133780002593994,\n",
            "                   'test/DER': 1.448022484779358,\n",
            "                   'test/SER': 12.016425132751465}],\n",
            " 'best_checkpoint': ''}\n"
          ]
        }
      ],
      "source": [
        "# Single-user testing\n",
        "!python -m emg2qwerty.train \\\n",
        "  user=\"single_user\" \\\n",
        "  checkpoint=\"/home/yigit/codebase/emg2qwerty/logs/2025-03-08/CNNLSTM/cnnlstm/checkpoints/best_checkpoint_cnn_lstm.ckpt\" \\\n",
        "  train=False trainer.accelerator=gpu \\\n",
        "  decoder=ctc_greedy \\\n",
        "  hydra.launcher.mem_gb=64 \\\n",
        "  # --multirun"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### 3. CNN + GRU Module"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[2025-03-11 00:38:00,468][HYDRA] Submitit 'local' sweep output dir : logs/2025-03-11/00-38-00\n",
            "[2025-03-11 00:38:00,469][HYDRA] \t#0 : user=single_user trainer.accelerator=gpu trainer.devices=4\n"
          ]
        }
      ],
      "source": [
        "# Single-user training\n",
        "!HYDRA_FULL_ERROR=1 python -m emg2qwerty.train \\\n",
        "  user=\"glob(single_user)\" \\\n",
        "  trainer.accelerator=gpu trainer.devices=4 \\\n",
        "  --multirun "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[2025-03-11 01:04:14,936][__main__][INFO] - \n",
            "Config:\n",
            "user: single_user\n",
            "dataset:\n",
            "  train:\n",
            "  - user: 89335547\n",
            "    session: 2021-06-03-1622765527-keystrokes-dca-study@1-0efbe614-9ae6-4131-9192-4398359b4f5f\n",
            "  - user: 89335547\n",
            "    session: 2021-06-02-1622681518-keystrokes-dca-study@1-0efbe614-9ae6-4131-9192-4398359b4f5f\n",
            "  - user: 89335547\n",
            "    session: 2021-06-04-1622863166-keystrokes-dca-study@1-0efbe614-9ae6-4131-9192-4398359b4f5f\n",
            "  - user: 89335547\n",
            "    session: 2021-07-22-1627003020-keystrokes-dca-study@1-0efbe614-9ae6-4131-9192-4398359b4f5f\n",
            "  - user: 89335547\n",
            "    session: 2021-07-21-1626916256-keystrokes-dca-study@1-0efbe614-9ae6-4131-9192-4398359b4f5f\n",
            "  - user: 89335547\n",
            "    session: 2021-07-22-1627004019-keystrokes-dca-study@1-0efbe614-9ae6-4131-9192-4398359b4f5f\n",
            "  - user: 89335547\n",
            "    session: 2021-06-05-1622885888-keystrokes-dca-study@1-0efbe614-9ae6-4131-9192-4398359b4f5f\n",
            "  - user: 89335547\n",
            "    session: 2021-06-02-1622679967-keystrokes-dca-study@1-0efbe614-9ae6-4131-9192-4398359b4f5f\n",
            "  - user: 89335547\n",
            "    session: 2021-06-03-1622764398-keystrokes-dca-study@1-0efbe614-9ae6-4131-9192-4398359b4f5f\n",
            "  - user: 89335547\n",
            "    session: 2021-07-21-1626917264-keystrokes-dca-study@1-0efbe614-9ae6-4131-9192-4398359b4f5f\n",
            "  - user: 89335547\n",
            "    session: 2021-06-05-1622889105-keystrokes-dca-study@1-0efbe614-9ae6-4131-9192-4398359b4f5f\n",
            "  - user: 89335547\n",
            "    session: 2021-06-03-1622766673-keystrokes-dca-study@1-0efbe614-9ae6-4131-9192-4398359b4f5f\n",
            "  - user: 89335547\n",
            "    session: 2021-06-04-1622861066-keystrokes-dca-study@1-0efbe614-9ae6-4131-9192-4398359b4f5f\n",
            "  - user: 89335547\n",
            "    session: 2021-07-22-1627001995-keystrokes-dca-study@1-0efbe614-9ae6-4131-9192-4398359b4f5f\n",
            "  - user: 89335547\n",
            "    session: 2021-06-05-1622884635-keystrokes-dca-study@1-0efbe614-9ae6-4131-9192-4398359b4f5f\n",
            "  - user: 89335547\n",
            "    session: 2021-07-21-1626915176-keystrokes-dca-study@1-0efbe614-9ae6-4131-9192-4398359b4f5f\n",
            "  val:\n",
            "  - user: 89335547\n",
            "    session: 2021-06-04-1622862148-keystrokes-dca-study@1-0efbe614-9ae6-4131-9192-4398359b4f5f\n",
            "  test:\n",
            "  - user: 89335547\n",
            "    session: 2021-06-02-1622682789-keystrokes-dca-study@1-0efbe614-9ae6-4131-9192-4398359b4f5f\n",
            "  root: ${hydra:runtime.cwd}/data\n",
            "to_tensor:\n",
            "  _target_: emg2qwerty.transforms.ToTensor\n",
            "  fields:\n",
            "  - emg_left\n",
            "  - emg_right\n",
            "band_rotation:\n",
            "  _target_: emg2qwerty.transforms.ForEach\n",
            "  transform:\n",
            "    _target_: emg2qwerty.transforms.RandomBandRotation\n",
            "    offsets:\n",
            "    - -1\n",
            "    - 0\n",
            "    - 1\n",
            "temporal_jitter:\n",
            "  _target_: emg2qwerty.transforms.TemporalAlignmentJitter\n",
            "  max_offset: 120\n",
            "logspec:\n",
            "  _target_: emg2qwerty.transforms.LogSpectrogram\n",
            "  n_fft: 64\n",
            "  hop_length: 16\n",
            "specaug:\n",
            "  _target_: emg2qwerty.transforms.SpecAugment\n",
            "  n_time_masks: 3\n",
            "  time_mask_param: 25\n",
            "  n_freq_masks: 2\n",
            "  freq_mask_param: 4\n",
            "transforms:\n",
            "  train:\n",
            "  - ${to_tensor}\n",
            "  - ${band_rotation}\n",
            "  - ${temporal_jitter}\n",
            "  - ${logspec}\n",
            "  - ${specaug}\n",
            "  val:\n",
            "  - ${to_tensor}\n",
            "  - ${logspec}\n",
            "  test: ${transforms.val}\n",
            "module:\n",
            "  _target_: emg2qwerty.lightning.CNNGRUModule\n",
            "  in_features: 528\n",
            "  cnn_channels:\n",
            "  - 32\n",
            "  - 64\n",
            "  - 128\n",
            "  - 256\n",
            "  gru_hidden_size: 512\n",
            "  gru_num_layers: 2\n",
            "  dropout: 0.2\n",
            "  adaptive_pool_size: 1\n",
            "datamodule:\n",
            "  _target_: emg2qwerty.lightning.WindowedEMGDataModule\n",
            "  window_length: 8000\n",
            "  padding:\n",
            "  - 1800\n",
            "  - 200\n",
            "optimizer:\n",
            "  _target_: torch.optim.Adam\n",
            "  lr: 0.001\n",
            "lr_scheduler:\n",
            "  scheduler:\n",
            "    _target_: pl_bolts.optimizers.lr_scheduler.LinearWarmupCosineAnnealingLR\n",
            "    warmup_epochs: 10\n",
            "    max_epochs: ${trainer.max_epochs}\n",
            "    warmup_start_lr: 1.0e-08\n",
            "    eta_min: 1.0e-06\n",
            "  interval: epoch\n",
            "decoder:\n",
            "  _target_: emg2qwerty.decoder.CTCGreedyDecoder\n",
            "seed: 1501\n",
            "batch_size: 32\n",
            "num_workers: 4\n",
            "train: false\n",
            "checkpoint: /home/yigit/codebase/emg2qwerty/logs/2025-03-11/CNN_GRU/cnn_gru/checkpoints/best_checkpoint_rnn_gru.ckpt\n",
            "monitor_metric: val/CER\n",
            "monitor_mode: min\n",
            "trainer:\n",
            "  accelerator: gpu\n",
            "  devices: 1\n",
            "  num_nodes: 1\n",
            "  max_epochs: 150\n",
            "  default_root_dir: ${hydra:runtime.output_dir}\n",
            "callbacks:\n",
            "- _target_: pytorch_lightning.callbacks.LearningRateMonitor\n",
            "- _target_: pytorch_lightning.callbacks.ModelCheckpoint\n",
            "  dirpath: ${hydra:runtime.output_dir}/checkpoints\n",
            "  monitor: ${monitor_metric}\n",
            "  mode: ${monitor_mode}\n",
            "  save_last: true\n",
            "  verbose: true\n",
            "\n",
            "Global seed set to 1501\n",
            "[2025-03-11 01:04:14,938][__main__][INFO] - Instantiating LightningModule {'_target_': 'emg2qwerty.lightning.CNNGRUModule', 'in_features': 528, 'cnn_channels': [32, 64, 128, 256], 'gru_hidden_size': 512, 'gru_num_layers': 2, 'dropout': 0.2, 'adaptive_pool_size': 1}\n",
            "[2025-03-11 01:04:15,077][__main__][INFO] - Loading module from checkpoint /home/yigit/codebase/emg2qwerty/logs/2025-03-11/CNN_GRU/cnn_gru/checkpoints/best_checkpoint_rnn_gru.ckpt\n",
            "[2025-03-11 01:04:15,177][__main__][INFO] - Instantiating LightningDataModule {'_target_': 'emg2qwerty.lightning.WindowedEMGDataModule', 'window_length': 8000, 'padding': [1800, 200]}\n",
            "GPU available: True (cuda), used: True\n",
            "TPU available: False, using: 0 TPU cores\n",
            "IPU available: False, using: 0 IPUs\n",
            "HPU available: False, using: 0 HPUs\n",
            "Missing logger folder: /home/yigit/codebase/emg2qwerty/logs/2025-03-11/01-04-14/lightning_logs\n",
            "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
            "Validation DataLoader 0: 100%|████████████████████| 7/7 [00:01<00:00,  6.49it/s]\n",
            "────────────────────────────────────────────────────────────────────────────────\n",
            "     Validate metric           DataLoader 0\n",
            "────────────────────────────────────────────────────────────────────────────────\n",
            "         val/CER            14.687638282775879\n",
            "         val/DER            1.4399645328521729\n",
            "         val/IER             2.702702760696411\n",
            "         val/SER            10.544971466064453\n",
            "        val/loss            0.5212497115135193\n",
            "────────────────────────────────────────────────────────────────────────────────\n",
            "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
            "Testing DataLoader 0: 100%|███████████████████████| 1/1 [00:05<00:00,  5.58s/it]\n",
            "────────────────────────────────────────────────────────────────────────────────\n",
            "       Test metric             DataLoader 0\n",
            "────────────────────────────────────────────────────────────────────────────────\n",
            "        test/CER             42.81391906738281\n",
            "        test/DER                    0.0\n",
            "        test/IER             34.81737518310547\n",
            "        test/SER             7.996541976928711\n",
            "        test/loss            1.615680456161499\n",
            "────────────────────────────────────────────────────────────────────────────────\n",
            "{'val_metrics': [{'val/loss': 0.5212497115135193,\n",
            "                  'val/CER': 14.687638282775879,\n",
            "                  'val/IER': 2.702702760696411,\n",
            "                  'val/DER': 1.4399645328521729,\n",
            "                  'val/SER': 10.544971466064453}],\n",
            " 'test_metrics': [{'test/loss': 1.615680456161499,\n",
            "                   'test/CER': 42.81391906738281,\n",
            "                   'test/IER': 34.81737518310547,\n",
            "                   'test/DER': 0.0,\n",
            "                   'test/SER': 7.996541976928711}],\n",
            " 'best_checkpoint': ''}\n"
          ]
        }
      ],
      "source": [
        "# Single-user testing\n",
        "!python -m emg2qwerty.train \\\n",
        "  user=\"single_user\" \\\n",
        "  checkpoint=\"/home/yigit/codebase/emg2qwerty/logs/2025-03-11/CNN_GRU/cnn_gru/checkpoints/best_checkpoint_rnn_gru.ckpt\" \\\n",
        "  train=False trainer.accelerator=gpu \\\n",
        "  decoder=ctc_greedy \\\n",
        "  hydra.launcher.mem_gb=64 \\\n",
        "  # --multirun"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### 4. CNN + Transformer Module"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[2025-03-11 04:03:11,099][HYDRA] Submitit 'local' sweep output dir : logs/2025-03-11/04-03-10\n",
            "[2025-03-11 04:03:11,100][HYDRA] \t#0 : user=single_user trainer.accelerator=gpu trainer.devices=4 lr_scheduler=cosine_annealing_warm_restarts lr_scheduler.scheduler.T_0=10 lr_scheduler.scheduler.T_mult=2 lr_scheduler.scheduler.eta_min=1e-06 trainer.max_epochs=400\n",
            "Error executing job with overrides: ['user=single_user', 'trainer.accelerator=gpu', 'trainer.devices=4', 'lr_scheduler=cosine_annealing_warm_restarts', 'lr_scheduler.scheduler.T_0=10', 'lr_scheduler.scheduler.T_mult=2', 'lr_scheduler.scheduler.eta_min=1e-06', 'trainer.max_epochs=400']\n",
            "Traceback (most recent call last):\n",
            "  File \"/home/yigit/anaconda3/envs/emg2qwerty/lib/python3.10/runpy.py\", line 196, in _run_module_as_main\n",
            "    return _run_code(code, main_globals, None,\n",
            "  File \"/home/yigit/anaconda3/envs/emg2qwerty/lib/python3.10/runpy.py\", line 86, in _run_code\n",
            "    exec(code, run_globals)\n",
            "  File \"/home/yigit/codebase/emg2qwerty/emg2qwerty/train.py\", line 129, in <module>\n",
            "    main()\n",
            "  File \"/home/yigit/anaconda3/envs/emg2qwerty/lib/python3.10/site-packages/hydra/main.py\", line 94, in decorated_main\n",
            "    _run_hydra(\n",
            "  File \"/home/yigit/anaconda3/envs/emg2qwerty/lib/python3.10/site-packages/hydra/_internal/utils.py\", line 394, in _run_hydra\n",
            "    _run_app(\n",
            "  File \"/home/yigit/anaconda3/envs/emg2qwerty/lib/python3.10/site-packages/hydra/_internal/utils.py\", line 465, in _run_app\n",
            "    run_and_report(\n",
            "  File \"/home/yigit/anaconda3/envs/emg2qwerty/lib/python3.10/site-packages/hydra/_internal/utils.py\", line 223, in run_and_report\n",
            "    raise ex\n",
            "  File \"/home/yigit/anaconda3/envs/emg2qwerty/lib/python3.10/site-packages/hydra/_internal/utils.py\", line 220, in run_and_report\n",
            "    return func()\n",
            "  File \"/home/yigit/anaconda3/envs/emg2qwerty/lib/python3.10/site-packages/hydra/_internal/utils.py\", line 466, in <lambda>\n",
            "    lambda: hydra.multirun(\n",
            "  File \"/home/yigit/anaconda3/envs/emg2qwerty/lib/python3.10/site-packages/hydra/_internal/hydra.py\", line 162, in multirun\n",
            "    ret = sweeper.sweep(arguments=task_overrides)\n",
            "  File \"/home/yigit/anaconda3/envs/emg2qwerty/lib/python3.10/site-packages/hydra/_internal/core_plugins/basic_sweeper.py\", line 181, in sweep\n",
            "    _ = r.return_value\n",
            "  File \"/home/yigit/anaconda3/envs/emg2qwerty/lib/python3.10/site-packages/hydra/core/utils.py\", line 260, in return_value\n",
            "    raise self._return_value\n",
            "torch.multiprocessing.spawn.ProcessRaisedException: \n",
            "\n",
            "-- Process 3 terminated with the following error:\n",
            "Traceback (most recent call last):\n",
            "  File \"/home/yigit/anaconda3/envs/emg2qwerty/lib/python3.10/site-packages/torch/multiprocessing/spawn.py\", line 75, in _wrap\n",
            "    fn(i, *args)\n",
            "  File \"/home/yigit/anaconda3/envs/emg2qwerty/lib/python3.10/site-packages/pytorch_lightning/strategies/launchers/multiprocessing.py\", line 139, in _wrapping_function\n",
            "    results = function(*args, **kwargs)\n",
            "  File \"/home/yigit/anaconda3/envs/emg2qwerty/lib/python3.10/site-packages/pytorch_lightning/trainer/trainer.py\", line 645, in _fit_impl\n",
            "    self._run(model, ckpt_path=self.ckpt_path)\n",
            "  File \"/home/yigit/anaconda3/envs/emg2qwerty/lib/python3.10/site-packages/pytorch_lightning/trainer/trainer.py\", line 1098, in _run\n",
            "    results = self._run_stage()\n",
            "  File \"/home/yigit/anaconda3/envs/emg2qwerty/lib/python3.10/site-packages/pytorch_lightning/trainer/trainer.py\", line 1177, in _run_stage\n",
            "    self._run_train()\n",
            "  File \"/home/yigit/anaconda3/envs/emg2qwerty/lib/python3.10/site-packages/pytorch_lightning/trainer/trainer.py\", line 1200, in _run_train\n",
            "    self.fit_loop.run()\n",
            "  File \"/home/yigit/anaconda3/envs/emg2qwerty/lib/python3.10/site-packages/pytorch_lightning/loops/loop.py\", line 199, in run\n",
            "    self.advance(*args, **kwargs)\n",
            "  File \"/home/yigit/anaconda3/envs/emg2qwerty/lib/python3.10/site-packages/pytorch_lightning/loops/fit_loop.py\", line 267, in advance\n",
            "    self._outputs = self.epoch_loop.run(self._data_fetcher)\n",
            "  File \"/home/yigit/anaconda3/envs/emg2qwerty/lib/python3.10/site-packages/pytorch_lightning/loops/loop.py\", line 199, in run\n",
            "    self.advance(*args, **kwargs)\n",
            "  File \"/home/yigit/anaconda3/envs/emg2qwerty/lib/python3.10/site-packages/pytorch_lightning/loops/epoch/training_epoch_loop.py\", line 214, in advance\n",
            "    batch_output = self.batch_loop.run(kwargs)\n",
            "  File \"/home/yigit/anaconda3/envs/emg2qwerty/lib/python3.10/site-packages/pytorch_lightning/loops/loop.py\", line 199, in run\n",
            "    self.advance(*args, **kwargs)\n",
            "  File \"/home/yigit/anaconda3/envs/emg2qwerty/lib/python3.10/site-packages/pytorch_lightning/loops/batch/training_batch_loop.py\", line 88, in advance\n",
            "    outputs = self.optimizer_loop.run(optimizers, kwargs)\n",
            "  File \"/home/yigit/anaconda3/envs/emg2qwerty/lib/python3.10/site-packages/pytorch_lightning/loops/loop.py\", line 199, in run\n",
            "    self.advance(*args, **kwargs)\n",
            "  File \"/home/yigit/anaconda3/envs/emg2qwerty/lib/python3.10/site-packages/pytorch_lightning/loops/optimization/optimizer_loop.py\", line 200, in advance\n",
            "    result = self._run_optimization(kwargs, self._optimizers[self.optim_progress.optimizer_position])\n",
            "  File \"/home/yigit/anaconda3/envs/emg2qwerty/lib/python3.10/site-packages/pytorch_lightning/loops/optimization/optimizer_loop.py\", line 247, in _run_optimization\n",
            "    self._optimizer_step(optimizer, opt_idx, kwargs.get(\"batch_idx\", 0), closure)\n",
            "  File \"/home/yigit/anaconda3/envs/emg2qwerty/lib/python3.10/site-packages/pytorch_lightning/loops/optimization/optimizer_loop.py\", line 357, in _optimizer_step\n",
            "    self.trainer._call_lightning_module_hook(\n",
            "  File \"/home/yigit/anaconda3/envs/emg2qwerty/lib/python3.10/site-packages/pytorch_lightning/trainer/trainer.py\", line 1342, in _call_lightning_module_hook\n",
            "    output = fn(*args, **kwargs)\n",
            "  File \"/home/yigit/anaconda3/envs/emg2qwerty/lib/python3.10/site-packages/pytorch_lightning/core/module.py\", line 1661, in optimizer_step\n",
            "    optimizer.step(closure=optimizer_closure)\n",
            "  File \"/home/yigit/anaconda3/envs/emg2qwerty/lib/python3.10/site-packages/pytorch_lightning/core/optimizer.py\", line 169, in step\n",
            "    step_output = self._strategy.optimizer_step(self._optimizer, self._optimizer_idx, closure, **kwargs)\n",
            "  File \"/home/yigit/anaconda3/envs/emg2qwerty/lib/python3.10/site-packages/pytorch_lightning/strategies/strategy.py\", line 234, in optimizer_step\n",
            "    return self.precision_plugin.optimizer_step(\n",
            "  File \"/home/yigit/anaconda3/envs/emg2qwerty/lib/python3.10/site-packages/pytorch_lightning/plugins/precision/precision_plugin.py\", line 121, in optimizer_step\n",
            "    return optimizer.step(closure=closure, **kwargs)\n",
            "  File \"/home/yigit/anaconda3/envs/emg2qwerty/lib/python3.10/site-packages/torch/optim/lr_scheduler.py\", line 75, in wrapper\n",
            "    return wrapped(*args, **kwargs)\n",
            "  File \"/home/yigit/anaconda3/envs/emg2qwerty/lib/python3.10/site-packages/torch/optim/optimizer.py\", line 391, in wrapper\n",
            "    out = func(*args, **kwargs)\n",
            "  File \"/home/yigit/anaconda3/envs/emg2qwerty/lib/python3.10/site-packages/torch/optim/optimizer.py\", line 76, in _use_grad\n",
            "    ret = func(self, *args, **kwargs)\n",
            "  File \"/home/yigit/anaconda3/envs/emg2qwerty/lib/python3.10/site-packages/torch/optim/adam.py\", line 148, in step\n",
            "    loss = closure()\n",
            "  File \"/home/yigit/anaconda3/envs/emg2qwerty/lib/python3.10/site-packages/pytorch_lightning/plugins/precision/precision_plugin.py\", line 107, in _wrap_closure\n",
            "    closure_result = closure()\n",
            "  File \"/home/yigit/anaconda3/envs/emg2qwerty/lib/python3.10/site-packages/pytorch_lightning/loops/optimization/optimizer_loop.py\", line 147, in __call__\n",
            "    self._result = self.closure(*args, **kwargs)\n",
            "  File \"/home/yigit/anaconda3/envs/emg2qwerty/lib/python3.10/site-packages/pytorch_lightning/loops/optimization/optimizer_loop.py\", line 133, in closure\n",
            "    step_output = self._step_fn()\n",
            "  File \"/home/yigit/anaconda3/envs/emg2qwerty/lib/python3.10/site-packages/pytorch_lightning/loops/optimization/optimizer_loop.py\", line 406, in _training_step\n",
            "    training_step_output = self.trainer._call_strategy_hook(\"training_step\", *kwargs.values())\n",
            "  File \"/home/yigit/anaconda3/envs/emg2qwerty/lib/python3.10/site-packages/pytorch_lightning/trainer/trainer.py\", line 1480, in _call_strategy_hook\n",
            "    output = fn(*args, **kwargs)\n",
            "  File \"/home/yigit/anaconda3/envs/emg2qwerty/lib/python3.10/site-packages/pytorch_lightning/strategies/ddp_spawn.py\", line 280, in training_step\n",
            "    return self.model(*args, **kwargs)\n",
            "  File \"/home/yigit/anaconda3/envs/emg2qwerty/lib/python3.10/site-packages/torch/nn/modules/module.py\", line 1532, in _wrapped_call_impl\n",
            "    return self._call_impl(*args, **kwargs)\n",
            "  File \"/home/yigit/anaconda3/envs/emg2qwerty/lib/python3.10/site-packages/torch/nn/modules/module.py\", line 1541, in _call_impl\n",
            "    return forward_call(*args, **kwargs)\n",
            "  File \"/home/yigit/anaconda3/envs/emg2qwerty/lib/python3.10/site-packages/torch/nn/parallel/distributed.py\", line 1593, in forward\n",
            "    else self._run_ddp_forward(*inputs, **kwargs)\n",
            "  File \"/home/yigit/anaconda3/envs/emg2qwerty/lib/python3.10/site-packages/torch/nn/parallel/distributed.py\", line 1411, in _run_ddp_forward\n",
            "    return self.module(*inputs, **kwargs)  # type: ignore[index]\n",
            "  File \"/home/yigit/anaconda3/envs/emg2qwerty/lib/python3.10/site-packages/torch/nn/modules/module.py\", line 1532, in _wrapped_call_impl\n",
            "    return self._call_impl(*args, **kwargs)\n",
            "  File \"/home/yigit/anaconda3/envs/emg2qwerty/lib/python3.10/site-packages/torch/nn/modules/module.py\", line 1541, in _call_impl\n",
            "    return forward_call(*args, **kwargs)\n",
            "  File \"/home/yigit/anaconda3/envs/emg2qwerty/lib/python3.10/site-packages/pytorch_lightning/overrides/base.py\", line 98, in forward\n",
            "    output = self._forward_module.training_step(*inputs, **kwargs)\n",
            "  File \"/home/yigit/codebase/emg2qwerty/emg2qwerty/lightning.py\", line 880, in training_step\n",
            "    return self._step(\"train\", *args, **kwargs)\n",
            "  File \"/home/yigit/codebase/emg2qwerty/emg2qwerty/lightning.py\", line 842, in _step\n",
            "    emissions = self.forward(inputs)\n",
            "  File \"/home/yigit/codebase/emg2qwerty/emg2qwerty/lightning.py\", line 758, in forward\n",
            "    x = self.spec_norm(inputs)\n",
            "  File \"/home/yigit/anaconda3/envs/emg2qwerty/lib/python3.10/site-packages/torch/nn/modules/module.py\", line 1532, in _wrapped_call_impl\n",
            "    return self._call_impl(*args, **kwargs)\n",
            "  File \"/home/yigit/anaconda3/envs/emg2qwerty/lib/python3.10/site-packages/torch/nn/modules/module.py\", line 1541, in _call_impl\n",
            "    return forward_call(*args, **kwargs)\n",
            "  File \"/home/yigit/codebase/emg2qwerty/emg2qwerty/modules.py\", line 409, in forward\n",
            "    inputs = self.layers[name](inputs)\n",
            "  File \"/home/yigit/anaconda3/envs/emg2qwerty/lib/python3.10/site-packages/torch/nn/modules/module.py\", line 1532, in _wrapped_call_impl\n",
            "    return self._call_impl(*args, **kwargs)\n",
            "  File \"/home/yigit/anaconda3/envs/emg2qwerty/lib/python3.10/site-packages/torch/nn/modules/module.py\", line 1541, in _call_impl\n",
            "    return forward_call(*args, **kwargs)\n",
            "  File \"/home/yigit/codebase/emg2qwerty/emg2qwerty/modules.py\", line 353, in forward\n",
            "    output = inputs * scales.unsqueeze(0)\n",
            "RuntimeError: The size of tensor a (32) must match the size of tensor b (621) at non-singleton dimension 1\n",
            "\n"
          ]
        }
      ],
      "source": [
        "!HYDRA_FULL_ERROR=1 \\\n",
        "  python -m emg2qwerty.train \\\n",
        "  user=\"glob(single_user)\" \\\n",
        "  trainer.accelerator=gpu trainer.devices=4 \\\n",
        "  lr_scheduler=cosine_annealing_warm_restarts \\\n",
        "  lr_scheduler.scheduler.T_0=10 \\\n",
        "  lr_scheduler.scheduler.T_mult=2 \\\n",
        "  lr_scheduler.scheduler.eta_min=1e-6 \\\n",
        "  trainer.max_epochs=400 \\\n",
        "  --multirun "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[2025-03-11 01:43:25,795][__main__][INFO] - \n",
            "Config:\n",
            "user: single_user\n",
            "dataset:\n",
            "  train:\n",
            "  - user: 89335547\n",
            "    session: 2021-06-03-1622765527-keystrokes-dca-study@1-0efbe614-9ae6-4131-9192-4398359b4f5f\n",
            "  - user: 89335547\n",
            "    session: 2021-06-02-1622681518-keystrokes-dca-study@1-0efbe614-9ae6-4131-9192-4398359b4f5f\n",
            "  - user: 89335547\n",
            "    session: 2021-06-04-1622863166-keystrokes-dca-study@1-0efbe614-9ae6-4131-9192-4398359b4f5f\n",
            "  - user: 89335547\n",
            "    session: 2021-07-22-1627003020-keystrokes-dca-study@1-0efbe614-9ae6-4131-9192-4398359b4f5f\n",
            "  - user: 89335547\n",
            "    session: 2021-07-21-1626916256-keystrokes-dca-study@1-0efbe614-9ae6-4131-9192-4398359b4f5f\n",
            "  - user: 89335547\n",
            "    session: 2021-07-22-1627004019-keystrokes-dca-study@1-0efbe614-9ae6-4131-9192-4398359b4f5f\n",
            "  - user: 89335547\n",
            "    session: 2021-06-05-1622885888-keystrokes-dca-study@1-0efbe614-9ae6-4131-9192-4398359b4f5f\n",
            "  - user: 89335547\n",
            "    session: 2021-06-02-1622679967-keystrokes-dca-study@1-0efbe614-9ae6-4131-9192-4398359b4f5f\n",
            "  - user: 89335547\n",
            "    session: 2021-06-03-1622764398-keystrokes-dca-study@1-0efbe614-9ae6-4131-9192-4398359b4f5f\n",
            "  - user: 89335547\n",
            "    session: 2021-07-21-1626917264-keystrokes-dca-study@1-0efbe614-9ae6-4131-9192-4398359b4f5f\n",
            "  - user: 89335547\n",
            "    session: 2021-06-05-1622889105-keystrokes-dca-study@1-0efbe614-9ae6-4131-9192-4398359b4f5f\n",
            "  - user: 89335547\n",
            "    session: 2021-06-03-1622766673-keystrokes-dca-study@1-0efbe614-9ae6-4131-9192-4398359b4f5f\n",
            "  - user: 89335547\n",
            "    session: 2021-06-04-1622861066-keystrokes-dca-study@1-0efbe614-9ae6-4131-9192-4398359b4f5f\n",
            "  - user: 89335547\n",
            "    session: 2021-07-22-1627001995-keystrokes-dca-study@1-0efbe614-9ae6-4131-9192-4398359b4f5f\n",
            "  - user: 89335547\n",
            "    session: 2021-06-05-1622884635-keystrokes-dca-study@1-0efbe614-9ae6-4131-9192-4398359b4f5f\n",
            "  - user: 89335547\n",
            "    session: 2021-07-21-1626915176-keystrokes-dca-study@1-0efbe614-9ae6-4131-9192-4398359b4f5f\n",
            "  val:\n",
            "  - user: 89335547\n",
            "    session: 2021-06-04-1622862148-keystrokes-dca-study@1-0efbe614-9ae6-4131-9192-4398359b4f5f\n",
            "  test:\n",
            "  - user: 89335547\n",
            "    session: 2021-06-02-1622682789-keystrokes-dca-study@1-0efbe614-9ae6-4131-9192-4398359b4f5f\n",
            "  root: ${hydra:runtime.cwd}/data\n",
            "to_tensor:\n",
            "  _target_: emg2qwerty.transforms.ToTensor\n",
            "  fields:\n",
            "  - emg_left\n",
            "  - emg_right\n",
            "band_rotation:\n",
            "  _target_: emg2qwerty.transforms.ForEach\n",
            "  transform:\n",
            "    _target_: emg2qwerty.transforms.RandomBandRotation\n",
            "    offsets:\n",
            "    - -1\n",
            "    - 0\n",
            "    - 1\n",
            "temporal_jitter:\n",
            "  _target_: emg2qwerty.transforms.TemporalAlignmentJitter\n",
            "  max_offset: 120\n",
            "logspec:\n",
            "  _target_: emg2qwerty.transforms.LogSpectrogram\n",
            "  n_fft: 64\n",
            "  hop_length: 16\n",
            "specaug:\n",
            "  _target_: emg2qwerty.transforms.SpecAugment\n",
            "  n_time_masks: 3\n",
            "  time_mask_param: 25\n",
            "  n_freq_masks: 2\n",
            "  freq_mask_param: 4\n",
            "transforms:\n",
            "  train:\n",
            "  - ${to_tensor}\n",
            "  - ${band_rotation}\n",
            "  - ${temporal_jitter}\n",
            "  - ${logspec}\n",
            "  - ${specaug}\n",
            "  val:\n",
            "  - ${to_tensor}\n",
            "  - ${logspec}\n",
            "  test: ${transforms.val}\n",
            "module:\n",
            "  _target_: emg2qwerty.lightning.CNNTransformerModule\n",
            "  in_features: 528\n",
            "  cnn_channels:\n",
            "  - 64\n",
            "  - 128\n",
            "  - 256\n",
            "  kernel_size: 3\n",
            "  transformer_dim: 512\n",
            "  nhead: 8\n",
            "  num_encoder_layers: 6\n",
            "  dim_feedforward: 1024\n",
            "  dropout: 0.2\n",
            "  max_seq_length: 10000\n",
            "  chunk_size: 512\n",
            "  chunk_overlap: 128\n",
            "datamodule:\n",
            "  _target_: emg2qwerty.lightning.WindowedEMGDataModule\n",
            "  window_length: 8000\n",
            "  padding:\n",
            "  - 1800\n",
            "  - 200\n",
            "optimizer:\n",
            "  _target_: torch.optim.Adam\n",
            "  lr: 0.001\n",
            "lr_scheduler:\n",
            "  scheduler:\n",
            "    _target_: pl_bolts.optimizers.lr_scheduler.LinearWarmupCosineAnnealingLR\n",
            "    warmup_epochs: 10\n",
            "    max_epochs: ${trainer.max_epochs}\n",
            "    warmup_start_lr: 1.0e-08\n",
            "    eta_min: 1.0e-06\n",
            "  interval: epoch\n",
            "decoder:\n",
            "  _target_: emg2qwerty.decoder.CTCGreedyDecoder\n",
            "seed: 1501\n",
            "batch_size: 32\n",
            "num_workers: 4\n",
            "train: false\n",
            "checkpoint: /home/yigit/codebase/emg2qwerty/epoch_149-step_4500.ckpt\n",
            "monitor_metric: val/CER\n",
            "monitor_mode: min\n",
            "trainer:\n",
            "  accelerator: gpu\n",
            "  devices: 1\n",
            "  num_nodes: 1\n",
            "  max_epochs: 150\n",
            "  default_root_dir: ${hydra:runtime.output_dir}\n",
            "callbacks:\n",
            "- _target_: pytorch_lightning.callbacks.LearningRateMonitor\n",
            "- _target_: pytorch_lightning.callbacks.ModelCheckpoint\n",
            "  dirpath: ${hydra:runtime.output_dir}/checkpoints\n",
            "  monitor: ${monitor_metric}\n",
            "  mode: ${monitor_mode}\n",
            "  save_last: true\n",
            "  verbose: true\n",
            "\n",
            "Global seed set to 1501\n",
            "[2025-03-11 01:43:25,798][__main__][INFO] - Instantiating LightningModule {'_target_': 'emg2qwerty.lightning.CNNTransformerModule', 'in_features': 528, 'cnn_channels': [64, 128, 256], 'kernel_size': 3, 'transformer_dim': 512, 'nhead': 8, 'num_encoder_layers': 6, 'dim_feedforward': 1024, 'dropout': 0.2, 'max_seq_length': 10000, 'chunk_size': 512, 'chunk_overlap': 128}\n",
            "/home/yigit/anaconda3/envs/emg2qwerty/lib/python3.10/site-packages/torch/nn/modules/transformer.py:306: UserWarning: enable_nested_tensor is True, but self.use_nested_tensor is False because encoder_layer.norm_first was True\n",
            "  warnings.warn(f\"enable_nested_tensor is True, but self.use_nested_tensor is False because {why_not_sparsity_fast_path}\")\n",
            "[2025-03-11 01:43:25,936][__main__][INFO] - Loading module from checkpoint /home/yigit/codebase/emg2qwerty/epoch_149-step_4500.ckpt\n",
            "[2025-03-11 01:43:26,046][__main__][INFO] - Instantiating LightningDataModule {'_target_': 'emg2qwerty.lightning.WindowedEMGDataModule', 'window_length': 8000, 'padding': [1800, 200]}\n",
            "GPU available: True (cuda), used: True\n",
            "TPU available: False, using: 0 TPU cores\n",
            "IPU available: False, using: 0 IPUs\n",
            "HPU available: False, using: 0 HPUs\n",
            "Missing logger folder: /home/yigit/codebase/emg2qwerty/logs/2025-03-11/01-43-25/lightning_logs\n",
            "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
            "Validation DataLoader 0: 100%|████████████████████| 7/7 [00:00<00:00,  7.73it/s]\n",
            "────────────────────────────────────────────────────────────────────────────────\n",
            "     Validate metric           DataLoader 0\n",
            "────────────────────────────────────────────────────────────────────────────────\n",
            "         val/CER            38.480281829833984\n",
            "         val/DER            3.4116082191467285\n",
            "         val/IER            22.396987915039062\n",
            "         val/SER            12.671688079833984\n",
            "        val/loss             1.130360722541809\n",
            "────────────────────────────────────────────────────────────────────────────────\n",
            "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
            "Testing DataLoader 0: 100%|███████████████████████| 1/1 [00:01<00:00,  1.78s/it]\n",
            "────────────────────────────────────────────────────────────────────────────────\n",
            "       Test metric             DataLoader 0\n",
            "────────────────────────────────────────────────────────────────────────────────\n",
            "        test/CER            42.770694732666016\n",
            "        test/DER            0.7564296722412109\n",
            "        test/IER            29.997838973999023\n",
            "        test/SER            12.016425132751465\n",
            "        test/loss           1.2082916498184204\n",
            "────────────────────────────────────────────────────────────────────────────────\n",
            "{'val_metrics': [{'val/loss': 1.130360722541809,\n",
            "                  'val/CER': 38.480281829833984,\n",
            "                  'val/IER': 22.396987915039062,\n",
            "                  'val/DER': 3.4116082191467285,\n",
            "                  'val/SER': 12.671688079833984}],\n",
            " 'test_metrics': [{'test/loss': 1.2082916498184204,\n",
            "                   'test/CER': 42.770694732666016,\n",
            "                   'test/IER': 29.997838973999023,\n",
            "                   'test/DER': 0.7564296722412109,\n",
            "                   'test/SER': 12.016425132751465}],\n",
            " 'best_checkpoint': ''}\n"
          ]
        }
      ],
      "source": [
        "# Single-user testing\n",
        "!python -m emg2qwerty.train \\\n",
        "  user=\"single_user\" \\\n",
        "  checkpoint=\"/home/yigit/codebase/emg2qwerty/epoch_149-step_4500.ckpt\" \\\n",
        "  train=False trainer.accelerator=gpu \\\n",
        "  decoder=ctc_greedy \\\n",
        "  hydra.launcher.mem_gb=64 \\\n",
        "  # --multirun"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Baseline Preprocessing and Data Augmentation Experiments"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "1. Data Preprocessing"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[2025-03-10 23:28:16,284][HYDRA] Submitit 'local' sweep output dir : logs/2025-03-10/23-28-16\n",
            "[2025-03-10 23:28:16,285][HYDRA] \t#0 : user=single_user trainer.accelerator=gpu trainer.devices=4\n",
            "Error executing job with overrides: ['user=single_user', 'trainer.accelerator=gpu', 'trainer.devices=4']\n",
            "Traceback (most recent call last):\n",
            "  File \"/home/yigit/anaconda3/envs/emg2qwerty/lib/python3.10/runpy.py\", line 196, in _run_module_as_main\n",
            "    return _run_code(code, main_globals, None,\n",
            "  File \"/home/yigit/anaconda3/envs/emg2qwerty/lib/python3.10/runpy.py\", line 86, in _run_code\n",
            "    exec(code, run_globals)\n",
            "  File \"/home/yigit/codebase/emg2qwerty/emg2qwerty/train.py\", line 129, in <module>\n",
            "    main()\n",
            "  File \"/home/yigit/anaconda3/envs/emg2qwerty/lib/python3.10/site-packages/hydra/main.py\", line 94, in decorated_main\n",
            "    _run_hydra(\n",
            "  File \"/home/yigit/anaconda3/envs/emg2qwerty/lib/python3.10/site-packages/hydra/_internal/utils.py\", line 394, in _run_hydra\n",
            "    _run_app(\n",
            "  File \"/home/yigit/anaconda3/envs/emg2qwerty/lib/python3.10/site-packages/hydra/_internal/utils.py\", line 465, in _run_app\n",
            "    run_and_report(\n",
            "  File \"/home/yigit/anaconda3/envs/emg2qwerty/lib/python3.10/site-packages/hydra/_internal/utils.py\", line 223, in run_and_report\n",
            "    raise ex\n",
            "  File \"/home/yigit/anaconda3/envs/emg2qwerty/lib/python3.10/site-packages/hydra/_internal/utils.py\", line 220, in run_and_report\n",
            "    return func()\n",
            "  File \"/home/yigit/anaconda3/envs/emg2qwerty/lib/python3.10/site-packages/hydra/_internal/utils.py\", line 466, in <lambda>\n",
            "    lambda: hydra.multirun(\n",
            "  File \"/home/yigit/anaconda3/envs/emg2qwerty/lib/python3.10/site-packages/hydra/_internal/hydra.py\", line 162, in multirun\n",
            "    ret = sweeper.sweep(arguments=task_overrides)\n",
            "  File \"/home/yigit/anaconda3/envs/emg2qwerty/lib/python3.10/site-packages/hydra/_internal/core_plugins/basic_sweeper.py\", line 181, in sweep\n",
            "    _ = r.return_value\n",
            "  File \"/home/yigit/anaconda3/envs/emg2qwerty/lib/python3.10/site-packages/hydra/core/utils.py\", line 260, in return_value\n",
            "    raise self._return_value\n",
            "hydra.errors.InstantiationException: Error locating target 'emg2qwerty.lightning.TDSConvCTCModule', set env var HYDRA_FULL_ERROR=1 to see chained exception.\n",
            "full_key: module\n"
          ]
        }
      ],
      "source": [
        "# Single-user training\n",
        "!HYDRA_FULL_ERROR=1 \\\n",
        "  python -m emg2qwerty.train \\\n",
        "  user=\"glob(single_user)\" \\\n",
        "  trainer.accelerator=gpu trainer.devices=4 \\\n",
        "  --multirun"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "emg2qwerty",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.13"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
